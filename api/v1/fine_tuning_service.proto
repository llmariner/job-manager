syntax = "proto3";

package llmariner.fine_tuning.server.v1;

import "google/api/annotations.proto";

option go_package = "github.com/llmariner/job-manager/api/v1";

// The API specification fllows OpenAPI API specification (https://platform.openai.com/docs/api-reference/fine-tuning/jobs).

message Integration {
  string type = 1;
  message Wandb {
    string project = 1;
    string name = 2;
    string entity = 3;
    repeated string tags = 4;
  }
  Wandb wandb = 2;
}

message Job {
  string id = 1;
  int64 created_at = 2;
  message Error {
    string code = 1;
    string message = 2;
    string param = 3;
  }
  Error error = 3;
  // The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.
  string fine_tuned_model = 4;
  int64 finished_at = 5;
  message Hyperparameters {
    // batch_size and learning_rate_multiplier are not part of
    // the OpenAI API spec, but we include here as these parameters are in CreateJobRequest.

    // Note: OpenAI API supports string or interger.
    int32 batch_size = 1;
    // Note: OpenAI API supports string or number.
    double learning_rate_multiplier = 2;
    // Note: OpenAI API supports string or interger.
    int32 n_epochs = 3;
  }
  Hyperparameters hyperparameters = 6;
  // The base model that is being fine-tuned.
  string model = 7;
  string object = 8;
  string organization_id = 9;
  repeated string result_files = 10;
  // The current status of the fine-tuning job, which can be either validating_files, queued, running, succeeded, failed, or cancelled.
  string status = 11;
  int32 trained_tokens = 12;
  string training_file = 13;
  string validation_file = 14;
  repeated Integration integrations = 15;
  int32 seed = 16;

  // The following fields are not part of the OpenAI API spec.

  string project_id = 17;
  string kubernetes_namespace = 18;
  // cluster_id is the ID of the cluster where he job runs.
  string cluster_id = 19;

  string organization_title = 20;
  string project_title = 21;
  string cluster_name = 22;

  message Resources {
    int32 gpu_count = 1;
  }
  Resources resources = 23;
}

message CreateJobRequest {
  string model = 1;
  string training_file = 2;
  message Hyperparameters {
    // Note: OpenAI API supports string or interger.
    int32 batch_size = 1;
    // Note: OpenAI API supports string or number.
    double learning_rate_multiplier = 2;
    // Note: OpenAI API supports string or interger.
    int32 n_epochs = 3;
  }
  Hyperparameters hyperparameters = 3;
  // A string of up to 18 characters that will be added to your fine-tuned model name.
  //
  // For example, a suffix of "custom-model-name" would produce a
  // model name like
  // ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel.
  string suffix = 4;
  string validation_file = 5;
  repeated Integration integrations = 6;
  int32 seed = 7;
  Job.Resources resources = 8;

  // metadata is not part of the OpenAI API spec, but if the key is "resources.gpu", the value
  // specify the number of GPUs allocated to the job. This is a workaround that allows users
  // to specify the number of GPUs with the OpenAI API Python client.
  map<string, string> metadata = 9;
}

message ListJobsRequest {
  // after is the identifier for the last job from the previous pagination request.
  string after = 1;
  // limit is the number of fine-tuning jobs to retrieve. Defaults to 20.
  int32 limit = 2;
}

message ListJobsResponse {
  string object = 1;
  repeated Job data = 2;
  bool has_more = 3;

  // total_items is the total number of batch jobs. This is not defined in the
  // OpenAI API spec, but we include here for better UX in the frontend.
  int32 total_items = 4;
}

message GetJobRequest {
  string id = 1;
}

message CancelJobRequest {
  string id = 1;
}

message InternalJob {
  Job job = 1;

  string output_model_id = 2;
  string suffix = 3;

  enum State {
    STATE_UNSPECIFIED = 0;
    QUEUED = 1;
    RUNNING = 2;
    FAILED = 3;
    SUCCEEDED = 4;
    CANCELED = 5;
  }
  // state is also stored in the job object, but this value takes precedence.
  State state = 4;

  enum Action {
    ACTION_UNSPECIFIED = 0;
    CREATING = 1;
    CANCELING = 2;
  }
  Action queued_action = 5;
}

message ListQueuedInternalJobsRequest {
}

message ListQueuedInternalJobsResponse {
  repeated InternalJob jobs = 1;
}

message GetInternalJobRequest {
  string id = 1;
}

message UpdateJobPhaseRequest {
  string id = 1;

  enum Phase {
    PHASE_UNSPECIFIED = 0;
    PREPROCESSED = 1;
    JOB_CREATED = 2;
    FINETUNED = 3;
    FAILED = 4;
    RECREATE = 5;
    CANCELED = 6;
  }
  Phase phase = 2;
  // message describing the details of the job phase. currently only used for failed jobs.
  string message = 3;
  // model_id is optional.
  string model_id = 4;
}

message UpdateJobPhaseResponse {
}

service FineTuningService {
  rpc CreateJob(CreateJobRequest) returns (Job) {
    option (google.api.http) = {
      post: "/v1/fine_tuning/jobs"
      body: "*"
    };
  }

  rpc ListJobs(ListJobsRequest) returns (ListJobsResponse) {
    option (google.api.http) = {
      get: "/v1/fine_tuning/jobs"
    };
  }

  rpc GetJob(GetJobRequest) returns (Job) {
    option (google.api.http) = {
      get: "/v1/fine_tuning/jobs/{id}"
    };
  }

  rpc CancelJob(CancelJobRequest) returns (Job) {
    option (google.api.http) = {
      post: "/v1/fine_tuning/jobs/{id}/cancel"
    };
  }
}

service FineTuningWorkerService {
  rpc ListQueuedInternalJobs(ListQueuedInternalJobsRequest) returns (ListQueuedInternalJobsResponse);
  rpc GetInternalJob(GetInternalJobRequest) returns (InternalJob);
  // UpdateJobPhase updates the job status depending on the phase.
  rpc UpdateJobPhase(UpdateJobPhaseRequest) returns (UpdateJobPhaseResponse);
}
